{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b4ff324",
   "metadata": {},
   "source": [
    "# Analyse Exploratoire des Données (EDA) - Que faire à Paris ?\n",
    "\n",
    "Ce notebook propose une analyse approfondie des événements culturels et loisirs à Paris, basés sur les données de l'API OpenData Paris.\n",
    "\n",
    "## Objectifs\n",
    "1. **Compréhension de la structure** : Identifier les variables clés et la qualité des données.\n",
    "2. **Nettoyage** : Traiter les valeurs manquantes, les doublons et formater les types de données.\n",
    "3. **Analyse Temporelle** : Étudier la saisonnalité et la durée des événements.\n",
    "4. **Analyse Géographique** : Visualiser la répartition spatiale des activités.\n",
    "5. **Analyse Textuelle** : Explorer les thématiques via les descriptions et les tags.\n",
    "6. **Analyse des Tarifs** : Comprendre la politique de prix (gratuité vs payant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0052d193",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Installation des dépendances si nécessaire\n",
    "%pip install pandas matplotlib seaborn plotly requests nbformat pymongo --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d226aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Settings for better visualization\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc677d3",
   "metadata": {},
   "source": [
    "## 1. Chargement et Récupération des Données depuis MongoDB\n",
    "\n",
    "Nous allons connecter le notebook à la base de données MongoDB hébergée dans le conteneur Docker.\n",
    "Assurez-vous que le conteneur MongoDB est en cours d'exécution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb5193cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MongoDB successfully.\n",
      "Found 0 documents in collection 'raw_events'.\n",
      "Dataset shape: (0, 0)\n"
     ]
    }
   ],
   "source": [
    "def get_data_from_mongo():\n",
    "    \"\"\"\n",
    "    Connects to local MongoDB and retrieves data from events_db.raw_events.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Connection params - connecting to localhost since port 27017 is forwarded\n",
    "        client = MongoClient(\n",
    "            host=\"localhost\",\n",
    "            port=27017,\n",
    "            username=\"admin\",\n",
    "            password=\"password\",\n",
    "            authSource=\"admin\",\n",
    "            serverSelectionTimeoutMS=5000\n",
    "        )\n",
    "        \n",
    "        # Check connection\n",
    "        client.admin.command('ping')\n",
    "        print(\"Connected to MongoDB successfully.\")\n",
    "        \n",
    "        db = client['events_db']\n",
    "        collection = db['raw_events']\n",
    "        \n",
    "        # Count documents\n",
    "        count = collection.count_documents({})\n",
    "        print(f\"Found {count} documents in collection 'raw_events'.\")\n",
    "        \n",
    "        if count == 0:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        # Fetch data (exclude _id for cleaner dataframe)\n",
    "        cursor = collection.find({}, {'_id': 0})\n",
    "        data = list(cursor)\n",
    "        \n",
    "        client.close()\n",
    "        return pd.DataFrame(data)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error connecting or retrieving data from MongoDB: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Load data\n",
    "df = get_data_from_mongo()\n",
    "\n",
    "# Display confirmation\n",
    "print(f\"Dataset shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ec0abe",
   "metadata": {},
   "source": [
    "## 2. Exploration de la Structure et Nettoyage Initial\n",
    "\n",
    "Avant toute analyse, il est crucial de comprendre les colonnes disponibles et de normaliser leurs noms si nécessaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a343a3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns found: []\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all columns to understand the schema\n",
    "print(\"Columns found:\", df.columns.tolist())\n",
    "\n",
    "# Display first few rows\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730f0363",
   "metadata": {},
   "source": [
    "### Identification des Valeurs Manquantes\n",
    "Visualisons les données manquantes pour identifier les colonnes exploitables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d75acf70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame est vide ou invalide. Impossible de tracer la heatmap.\n"
     ]
    }
   ],
   "source": [
    "if not df.empty and len(df) > 0:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.heatmap(df.isnull(), cbar=False, cmap='viridis', yticklabels=False)\n",
    "    plt.title(\"Carte des Valeurs Manquantes (Jaune = Manquant)\")\n",
    "    plt.show()\n",
    "\n",
    "    # Percentage of missing values per column\n",
    "    missing_percent = (df.isnull().sum() / len(df)) * 100\n",
    "    print(missing_percent[missing_percent > 0].sort_values(ascending=False))\n",
    "else:\n",
    "    print(\"DataFrame est vide ou invalide. Impossible de tracer la heatmap.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36df5c56",
   "metadata": {},
   "source": [
    "## 3. Analyse Temporelle\n",
    "\n",
    "Nous allons convertir les dates et analyser la fréquence des événements par mois et par jour de la semaine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d99a2638",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    # Convert date columns\n",
    "    date_columns = ['date_start', 'date_end']\n",
    "    for col in date_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "    # Feature Engineering: Month, Day of Week, Duration\n",
    "    if 'date_start' in df.columns:\n",
    "        df['start_month'] = df['date_start'].dt.month_name()\n",
    "        df['start_day'] = df['date_start'].dt.day_name()\n",
    "        df['year'] = df['date_start'].dt.year\n",
    "\n",
    "        # Calculate duration in days\n",
    "        if 'date_end' in df.columns:\n",
    "            df['duration_days'] = (df['date_end'] - df['date_start']).dt.days\n",
    "            df['duration_days'] = df['duration_days'].fillna(0)  # One day events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f471285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Events by Month\n",
    "if 'start_month' in df.columns:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "    valid_order = [m for m in order if m in df['start_month'].unique()]\n",
    "    sns.countplot(data=df, x='start_month', order=valid_order, palette='coolwarm')\n",
    "    plt.title(\"Nombre d'Événements par Mois\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b6b6d5",
   "metadata": {},
   "source": [
    "## 4. Analyse Géographique\n",
    "\n",
    "Où se déroulent les événements ? Utilisons les coordonnées GPS (lat/lon) si disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b315c962",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    # Clean Lat/Lon data\n",
    "    geo_cols_candidates = {'lat': ['lat', 'latitude'], 'lon': ['lon', 'long', 'longitude']}\n",
    "\n",
    "    # Find actual column names for latitude and longitude\n",
    "    lat_col, lon_col = None, None\n",
    "\n",
    "    for col in df.columns:\n",
    "        if col.lower() in geo_cols_candidates['lat']:\n",
    "            lat_col = col\n",
    "        if col.lower() in geo_cols_candidates['lon']:\n",
    "            lon_col = col\n",
    "\n",
    "    # If columns explicitly named like 'lat_lon' containing a dictionary/list exist\n",
    "    if not lat_col and 'lat_lon' in df.columns:\n",
    "        # Attempt to extract if it's a dictionary or object\n",
    "        try:\n",
    "            df['lat'] = df['lat_lon'].apply(lambda x: x['lat'] if isinstance(x, dict) else (x[0] if isinstance(x, list) else None))\n",
    "            df['lon'] = df['lat_lon'].apply(lambda x: x['lon'] if isinstance(x, dict) else (x[1] if isinstance(x, list) else None))\n",
    "            lat_col, lon_col = 'lat', 'lon'\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    if lat_col and lon_col:\n",
    "        # Remove invalid coordinates\n",
    "        df_geo = df.dropna(subset=[lat_col, lon_col])\n",
    "        \n",
    "        print(f\"Plotting map with {len(df_geo)} points\")\n",
    "        \n",
    "        fig = px.scatter_mapbox(df_geo, \n",
    "                                lat=lat_col, \n",
    "                                lon=lon_col, \n",
    "                                hover_name=\"title\" if \"title\" in df.columns else None, \n",
    "                                color=\"price_type\" if \"price_type\" in df.columns else None,\n",
    "                                zoom=11, \n",
    "                                height=600)\n",
    "        \n",
    "        fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "        fig.update_layout(title=\"Carte des Événements à Paris\")\n",
    "        fig.show()\n",
    "    else:\n",
    "        print(\"Coordonnées géographiques non trouvées (lat/lon).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ba8697",
   "metadata": {},
   "source": [
    "## 5. Analyse des Prix et de l'Accessibilité\n",
    "\n",
    "Comparons les événements gratuits et payants. Nous cherchons des colonnes comme `price_type`, `price_detail` ou `access_type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87f98062",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df.empty:\n",
    "    price_col_candidates = ['price_type', 'access_type', 'price_detail']\n",
    "    price_col = next((c for c in price_col_candidates if c in df.columns), None)\n",
    "\n",
    "    if price_col:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        # Get top 5 price types to avoid clutter\n",
    "        top_prices = df[price_col].value_counts().head(5).index\n",
    "        sns.countplot(data=df[df[price_col].isin(top_prices)], y=price_col, order=top_prices, palette='viridis')\n",
    "        plt.title(f\"Distribution des Types de Prix ({price_col})\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Aucune colonne explicite sur le type de prix trouvée.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b356278",
   "metadata": {},
   "source": [
    "## 6. Analyse Textuelle et Mots-Clés\n",
    "\n",
    "Extraction des mots les plus fréquents dans les titres et les descriptions pour comprendre les thématiques populaires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ac12f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Zà-ü\\s]', '', text) # Keep french accents\n",
    "    return text\n",
    "\n",
    "if not df.empty:\n",
    "    text_col = 'title' if 'title' in df.columns else ('title_fr' if 'title_fr' in df.columns else None)\n",
    "\n",
    "    if text_col:\n",
    "        all_text = \" \".join(df[text_col].dropna().apply(clean_text))\n",
    "        words = all_text.split()\n",
    "        \n",
    "        # Remove simple stop words\n",
    "        stop_words = set(['de', 'la', 'le', 'et', 'les', 'des', 'en', 'un', 'une', 'du', 'au', 'pour', 'sur', 'a', 'à', 'par', 'dans', 'ce', 'qui'])\n",
    "        filtered_words = [w for w in words if w not in stop_words and len(w) > 2]\n",
    "        \n",
    "        word_counts = Counter(filtered_words).most_common(20)\n",
    "        \n",
    "        # Plot\n",
    "        words_df = pd.DataFrame(word_counts, columns=['Word', 'Count'])\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.barplot(data=words_df, x='Count', y='Word', palette='magma')\n",
    "        plt.title(\"Top 20 des Mots dans les Titres\")\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Colonne de texte non trouvée.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3879971",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Ce notebook a permis de mettre en évidence :\n",
    "1. **La qualité des données** (colonnes manquantes, format des dates).\n",
    "2. **La dynamique temporelle** des événements.\n",
    "3. **La répartition géographique**.\n",
    "4. **Les thématiques principales** via l'analyse de texte.\n",
    "\n",
    "Ces insights sont essentiels pour orienter les futures étapes de modélisation ou de création de tableau de bord."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd0599d",
   "metadata": {},
   "source": [
    "# Analyse Exploratoire des Données (EDA) - Événements à Paris\n",
    "\n",
    "Ce notebook présente une analyse exploratoire des données récupérées depuis l'API OpenData de Paris concernant les événements \"Que faire à Paris ?\".\n",
    "\n",
    "L'objectif est de comprendre la structure des données, de nettoyer les informations et de visualiser quelques tendances clés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf1a278e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /home/angie/.local/lib/python3.14/site-packages (2.3.3)\n",
      "Requirement already satisfied: matplotlib in /home/angie/.local/lib/python3.14/site-packages (3.10.8)\n",
      "Requirement already satisfied: seaborn in /home/angie/.local/lib/python3.14/site-packages (0.13.2)\n",
      "Requirement already satisfied: plotly in /home/angie/.local/lib/python3.14/site-packages (6.5.2)\n",
      "Requirement already satisfied: requests in /usr/lib/python3.14/site-packages (2.32.5)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /usr/lib64/python3.14/site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/lib/python3.14/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/angie/.local/lib/python3.14/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/angie/.local/lib/python3.14/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/angie/.local/lib/python3.14/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/angie/.local/lib/python3.14/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/angie/.local/lib/python3.14/site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/angie/.local/lib/python3.14/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3.14/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/lib64/python3.14/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /usr/lib/python3.14/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /home/angie/.local/lib/python3.14/site-packages (from plotly) (2.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/lib/python3.14/site-packages (from requests) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3.14/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3.14/site-packages (from requests) (2.6.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3.14/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries if not already installed\n",
    "%pip install pandas matplotlib seaborn plotly requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c0470fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1c82fe",
   "metadata": {},
   "source": [
    "## 1. Récupération des Données\n",
    "Nous allons récupérer un échantillon de données directement depuis l'API pour l'analyse locale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2814e63c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from API...\n",
      "Error fetching data: 400 Client Error: Bad Request for url: https://opendata.paris.fr/api/explore/v2.1/catalog/datasets/que-faire-a-paris-/records?limit=1000&offset=0\n",
      "Data loaded: 0 rows, 0 columns\n"
     ]
    }
   ],
   "source": [
    "def fetch_data(limit=1000):\n",
    "    \"\"\"\n",
    "    Fetches data from the OpenData Paris API.\n",
    "    \"\"\"\n",
    "    base_url = \"https://opendata.paris.fr/api/explore/v2.1/catalog/datasets/que-faire-a-paris-/records\"\n",
    "    params = {\n",
    "        'limit': limit,\n",
    "        'offset': 0\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(base_url, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return data['results']\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return []\n",
    "\n",
    "# Fetch data sample\n",
    "print(\"Fetching data from API...\")\n",
    "events_data = fetch_data(limit=1000)\n",
    "df = pd.DataFrame(events_data)\n",
    "print(f\"Data loaded: {df.shape[0]} rows, {df.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b516b6",
   "metadata": {},
   "source": [
    "## 2. Aperçu des Données\n",
    "Inspectons les premières lignes et la structure du dataset pour comprendre les colonnes disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f17e8f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8844d517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 0 entries\n",
      "Empty DataFrame\n"
     ]
    }
   ],
   "source": [
    "# Display dataset information (types, missing values)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce4a8a8",
   "metadata": {},
   "source": [
    "## 3. Nettoyage des Données\n",
    "Nous allons convertir les colonnes de dates au bon format et vérifier les doublons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f04775f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Convert date columns to datetime objects\n",
    "date_cols = ['date_start', 'date_end']\n",
    "for col in date_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "\n",
    "# Remove duplicates if any\n",
    "if duplicates > 0:\n",
    "    df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68460f41",
   "metadata": {},
   "source": [
    "## 4. Analyse des Prix\n",
    "Regardons la répartition des types de prix (gratuit, payant, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f313407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'price_type' not found.\n"
     ]
    }
   ],
   "source": [
    "if 'price_type' in df.columns:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(data=df, x='price_type', order=df['price_type'].value_counts().index)\n",
    "    plt.title(\"Distribution des Types de Prix\")\n",
    "    plt.xlabel(\"Type de Prix\")\n",
    "    plt.ylabel(\"Nombre d'événements\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Column 'price_type' not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edd232a",
   "metadata": {},
   "source": [
    "## 5. Analyse Temporelle\n",
    "Observons la répartition des événements dans le temps (par mois/année)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f765ae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'date_start' in df.columns:\n",
    "    # Extract month and year\n",
    "    df['period'] = df['date_start'].dt.to_period('M')\n",
    "    \n",
    "    # Count events per period\n",
    "    period_counts = df['period'].value_counts().sort_index()\n",
    "    \n",
    "    plt.figure(figsize=(14, 6))\n",
    "    period_counts.plot(kind='bar', color='skyblue')\n",
    "    plt.title(\"Nombre d'événements par Mois\")\n",
    "    plt.xlabel(\"Période\")\n",
    "    plt.ylabel(\"Nombre d'événements\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693503c3",
   "metadata": {},
   "source": [
    "## 6. Analyse Géographique\n",
    "Si les coordonnées sont disponibles, nous pouvons voir où se situent les événements (top lieux)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58b8b2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'address_city' in df.columns:\n",
    "    top_cities = df['address_city'].value_counts().head(10)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(x=top_cities.values, y=top_cities.index, palette=\"viridis\")\n",
    "    plt.title(\"Top 10 des Villes (ou codes postaux) des Événements\")\n",
    "    plt.xlabel(\"Nombre d'événements\")\n",
    "    plt.ylabel(\"Ville\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
